{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7774577-a4f1-4cc5-8017-37a3c368e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from utilities import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d20e94-cbf3-4ee6-89c4-e031df922929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1.0\n",
    "\n",
    "labels_idx = [\"D00\",\"D10\",\"D20\",\"D40\"]\n",
    "\n",
    "class RoadDamageDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        \n",
    "        self.dir_xmls = os.path.join(folder, \"annotations\", \"xmls\")\n",
    "        self.dir_imgs = os.path.join(folder, \"images\")\n",
    "        \n",
    "        self.annotations = [os.path.join(self.dir_xmls, xml) for xml in os.listdir(self.dir_xmls)]\n",
    "        self.images_file = [os.path.join(self.dir_imgs, img) for img in os.listdir(self.dir_imgs)]\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        \n",
    "        image = Image.open(self.images_file[i])\n",
    "        tree = ET.parse(self.annotations[i])\n",
    "        objects = tree.findall(\"object\")\n",
    "\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for i, obj in enumerate(objects):\n",
    "            objectID = \"object_{:02d}\".format(i)\n",
    "            name = obj.find(\"name\").text\n",
    "            if name == 'Repair':\n",
    "                continue\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            xmin = int(bbox.find(\"xmin\").text)\n",
    "            ymin = int(bbox.find(\"ymin\").text)\n",
    "            xmax = int(bbox.find(\"xmax\").text)\n",
    "            ymax = int(bbox.find(\"ymax\").text)\n",
    "            \n",
    "            label = labels_idx.index(name)\n",
    "            labels.append(label)\n",
    "            bboxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        bboxes = torch.FloatTensor(bboxes)\n",
    "        labels = torch.FloatTensor(labels)\n",
    "        \n",
    "        image, bboxes, labels = transform(image, bboxes, labels)\n",
    "        \n",
    "        return image, bboxes, labels\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7dcac3-a261-40ad-a924-465dc5676481",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder =\"D:\\\\Dataset\\\\CRDDC2022\\\\dataset\\\\China_MotorBike\\\\train\\\\\"\n",
    "\n",
    "train_RDD = RoadDamageDataset(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2f7375-e726-4bbf-90bf-06fbc3c579ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, bboxes, labels = train_RDD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b367764-2867-402e-b964-fb84ec9d4266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.5982,  1.5810,  1.5297,  ...,  0.6734,  0.5536,  0.4508],\n",
      "         [ 1.5125,  1.5125,  1.4783,  ...,  0.5707,  0.6049,  0.4679],\n",
      "         [ 1.4783,  1.4612,  1.4098,  ...,  0.6563,  0.5364,  0.4508],\n",
      "         ...,\n",
      "         [ 0.3994,  0.5536,  0.4166,  ...,  0.1597,  0.1083,  0.2796],\n",
      "         [ 0.5536,  0.0056,  0.3652,  ..., -0.1828,  0.2624,  0.0398],\n",
      "         [ 0.4851,  0.0398,  0.5364,  ...,  0.3138,  0.4851,  0.3309]],\n",
      "\n",
      "        [[ 1.7633,  1.7633,  1.6933,  ...,  0.8179,  0.6954,  0.5903],\n",
      "         [ 1.6933,  1.6933,  1.6408,  ...,  0.7129,  0.7479,  0.6078],\n",
      "         [ 1.6583,  1.6408,  1.5882,  ...,  0.8004,  0.6779,  0.5903],\n",
      "         ...,\n",
      "         [ 0.5028,  0.6779,  0.5028,  ...,  0.2927,  0.2402,  0.4153],\n",
      "         [ 0.6429,  0.0826,  0.4678,  ..., -0.0574,  0.3978,  0.1702],\n",
      "         [ 0.6078,  0.1176,  0.6429,  ...,  0.4503,  0.6254,  0.4678]],\n",
      "\n",
      "        [[ 1.9080,  1.9080,  1.8383,  ...,  1.0539,  0.9494,  0.8448],\n",
      "         [ 1.8383,  1.8383,  1.7860,  ...,  0.9668,  1.0017,  0.8622],\n",
      "         [ 1.8034,  1.7860,  1.7337,  ...,  1.0365,  0.9319,  0.8448],\n",
      "         ...,\n",
      "         [ 0.7751,  0.9319,  0.7751,  ...,  0.5485,  0.4962,  0.6531],\n",
      "         [ 0.9319,  0.3742,  0.7402,  ...,  0.1825,  0.6356,  0.4091],\n",
      "         [ 0.8622,  0.4091,  0.9145,  ...,  0.6879,  0.8622,  0.7054]]])\n",
      "tensor([[0.3301, 0.0020, 1.0000, 0.3516],\n",
      "        [0.8184, 0.3516, 1.0000, 0.5762],\n",
      "        [0.2422, 0.0020, 0.2891, 0.0879]])\n",
      "tensor([2., 2., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(image)\n",
    "print(bboxes)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc8bd6-04bf-47c6-90a8-34344f210f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep]",
   "language": "python",
   "name": "conda-env-deep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
